# LegalDoc AI: Intelligent Document Analysis Framework

An engineering-inspired NLP framework designed to classify, analyze, and visualize scope-limited legal documents. This project leverages **Lawformer** (Legal-BERT) for semantic understanding and **Graph Theory** for information density optimization.



## üöÄ Key Engineering Pillars

### 1. Vector Space Model (VSM) Classifier
Documents are numerically represented in a high-dimensional space. The system calculates the **Cosine Proximity** between the document vector and domain centroids (Criminal, Contract, Education) to perform automated classification.

### 2. Graph Centrality Word Clouds
Unlike standard frequency-based clouds, our system builds a **Co-occurrence Graph** of legal terms. **Degree Centrality** is used to identify semantically "influential" terms, which are then passed to our visualization engine.

### 3. Greedy Knapsack Selection
To manage "Information Density," the system treats terms as items in a Knapsack problem. It selects the most "valuable" terms (highest centrality) that fit within a limited visual "budget," preventing UI clutter.

## üõ†Ô∏è Tech Stack
- **Backend:** FastAPI (Python), PyMuPDF, NetworkX, PyTorch, Lawformer (Transformers)
- **Frontend:** React 19, Vite, Material UI, Zustand, React-TagCloud


## üìÖ Project Management & Task Distribution

The development of **LegalDoc AI** followed a 15-week structured timeline, utilizing parallel task processing to ensure seamless integration between NLP models and the frontend interface.

### Task Distribution Matrix
| Task ID | Task Description | Assigned Member(s) | Start Week | End Week |
| :--- | :--- | :--- | :--- | :--- |
| **T1** | Requirement Gathering | All Members | 1 | 1 |
| **T2** | Literature Review | Tanishq | 2 | 3 |
| **T3** | Dataset Collection & Preprocessing | Nilakshi, Tanishq | 3 | 5 |
| **T4** | Model Design & Training | Nilakshi | 4 | 8 |
| **T5** | Backend Integration | Mansi | 6 | 10 |


## ‚öôÔ∏è Local Setup

### Backend
1. `cd backend`
2. `python -m venv venv`
3. `source venv/bin/activate` (or `venv\Scripts\activate` on Windows)
4. `pip install -r requirements.txt`
5. `uvicorn app.main:app --reload`

### Frontend
1. `cd frontend`
2. `npm install --legacy-peer-deps`
3. `npm run dev`

## üìä Methodology Reference
This implementation follows the research methodology outlined in:
*Tanishq Shinde, et al. "Intelligent Legal Document Analysis using NLP," Pune Institute of Computer Technology.*
## üñºÔ∏è Dashboard Overview

### 1. Ingestion Phase (Beginning UI)
The initial entry point where the binary PDF stream is captured and prepared for text extraction.
![Begin UI](https://github.com/user-attachments/assets/b35e6fc1-839b-4c93-bb15-6c641ffb8b2b)


### 2. Intelligent Risk Assessment (Text Extraction)
Actual text extracted from the PDF via PyMuPDF, with semantic highlights generated by the Lawformer model.
![Output text](https://github.com/user-attachments/assets/0d1bb9c7-2184-40b4-922b-86e1cd84addf)


### 3. Information Density Map (Word Cloud)
Visualization of domain-specific keywords selected through dynamic Graph Centrality and Knapsack optimization.
![wordcloud](https://github.com/user-attachments/assets/d1748380-23a5-4a36-8603-6f4f944203bf)

